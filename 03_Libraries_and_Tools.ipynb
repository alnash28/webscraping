{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Tools\n",
    "\n",
    "Below is an overview of the libraries and other tools used for webscraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Urllib](https://docs.python.org/3/library/urllib.html)\n",
    "\n",
    "Urllib is part of the Python standard library. It has several modules used for handling URLs (Uniform Resource Locators). \n",
    "\n",
    "* [`urllib.request`](https://docs.python.org/3/library/urllib.request.html#module-urllib.request) defines functions and classes which help in opening URLs (mostly HTTP) in a complex world â€” basic and digest authentication, redirections, cookies and more.\n",
    "* [`urllib.error`](https://docs.python.org/3/library/urllib.error.html#module-urllib.error) defines the exception classes for exceptions raised by urllib.request.\n",
    "* [`urllib.parse`](https://docs.python.org/3/library/urllib.parse.html#module-urllib.parse) defines a standard interface to break URL strings into components (addressing scheme, network location, path, etc.) and to build URLs from the components.\n",
    "* [`urllib.robotparser`](https://docs.python.org/3/library/urllib.robotparser.html#module-urllib.robotparser) uses a `RobotFileParser` class to answer questions about weather or not a particualr user agent can fetch a URL based on the [`robots.txt`](https://www.robotstxt.org/) file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Requests](https://requests.readthedocs.io/en/master/)\n",
    "\n",
    "Requests is a library that makes it easier to deal with HTTP requests. It is easy to get a web page with the `requests.get(url)` function. Requests can also generate POST requests to submit form data, handle sessions and cookies, handle SSL verification, and more.\n",
    "\n",
    "[Requests Toolbelt](https://toolbelt.readthedocs.io/en/latest/) is a library built to extend the Requests library. It is developed by the Requests core developers and contains tools that you might need, but don't fit into the Requests library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LXML](https://lxml.de/)\n",
    "\n",
    "LXML is a fast library for parsing XML documents (including HTML). It's built on top of C libraries [libxml2](http://xmlsoft.org/) and [libxslt](http://xmlsoft.org/XSLT/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/)\n",
    "\n",
    "BeautifulSoup is a parsing library that can use different parsers (such as LXML). It is easy to learn and allows you to quickly find specific elements on a page. BeautifulSoup has the ability to infer structure and can fix broken HTML and XML tags. BeautifulSoup will only parse static contnet, so it can not handle javascript generated websites. However, often enough it's easy to inspect the page and find the API calls which can be digested with Requests and other libraries like [json](https://docs.python.org/3/library/json.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Selenium](https://selenium.dev/selenium/docs/api/py/)\n",
    "\n",
    "Selenium is a web driver designed for rendering and testing webpages. It allows you to programatically interact with the web pages, which means you are also able to extract content from the page. The advantage to Selenium is that it will execute javascript and render all the content on the page. However, this will slow down the scraping process and might not be suitable for large scale projects.\n",
    "\n",
    "To run selenium, you need to have a web brower installed. Additionaly, you must download the appropriate web driver and place it in Selenium's path for Selenium to control the browser. The web drivers for common browsers can be found at the links below.\n",
    "\n",
    "* [Chrome](https://chromedriver.chromium.org/downloads)\n",
    "* [Firefox](https://github.com/mozilla/geckodriver/releases)\n",
    "* [Opera](https://github.com/operasoftware/operachromiumdriver/releases)\n",
    "* [Internet Explorer](https://github.com/SeleniumHQ/selenium/wiki/InternetExplorerDriver)\n",
    "* [Edge](https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/)\n",
    "* [Safari](https://developer.apple.com/documentation/webkit/testing_with_webdriver_in_safari)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scrapy](https://docs.scrapy.org/en/latest/)\n",
    "\n",
    "Scrapy is a web scraping framework designed for building spiders that crawl and process webpages. It combines the power of Reqeusts and BeautifulSoup in one place to allow you to quickly build scraping pipelines. Scrapy is built on top of [Twisted](https://twistedmatrix.com/trac/) which allows asynchronous requests to speed up the process. \n",
    "\n",
    "Like BeautifulSoup, Scrapy does not inherently render javascript. However, the creators of Scrapy have developed a headless lightweight browser called Splash specifically designed for web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Sites and References    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Web Scraping Sandbox](http://toscrape.com/)\n",
    "* [Fake Bookstore](http://books.toscrape.com/)\n",
    "* Real Quotes. There are several different configurations of this page to practice different scraping techniques.\n",
    "    * [Default: Microdata and pagination](http://quotes.toscrape.com/)\n",
    "    * [Scroll: Infinite scrolling pagination](http://quotes.toscrape.com/scroll)\n",
    "    * [JavaScript: JavaScript generated content](http://quotes.toscrape.com/js)\n",
    "    * [Tableful: A table based messed-up layout](http://quotes.toscrape.com/tableful)\n",
    "    * [Login: Login with CSRF token (any user/passwd works)](http://quotes.toscrape.com/login)\n",
    "    * [ViewState: An AJAX based filter form with ViewStates](http://quotes.toscrape.com/search.aspx)\n",
    "    * [Random: A single random quote](http://quotes.toscrape.com/random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
