{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Webpages with BeautifulSoup\n",
    "\n",
    "Welcome! This module will be a walkthrough to processing web data with the popular Python package BeautifulSoup.\n",
    "\n",
    "BeautifulSoup has a terrific [webpage for documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) that has in-depth installation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the hood of a webpage\n",
    "\n",
    "![](images/toscrape_screenshot.png)\n",
    "\n",
    "**Figure 1**: Every part of a webpage is generated from the underlying HTML. BeautifulSoup makes it easy to get this data and do cool things with it.\n",
    "\n",
    "#### Fortunately\n",
    "You don't need to know HTML to use BeautifulSoup, but it certainly helps.\n",
    "For example, if you know what you want from looking at the webpage, you may not understand how to HTML works underneath which will limit what your efficiency with BeautifulSoup. Otherwise, the more about HTML you know, the more effective a tool BeautifulSoup will be.\n",
    "<br><br><br>\n",
    "### Creating a soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the soup object \n",
    "url = 'http://quotes.toscrape.com'\n",
    "r  = requests.get(url)\n",
    "data = r.text\n",
    "soup = BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>Quotes to Scrape</title>\n",
      "<link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
      "<link href=\"/static/main.css\" rel=\"stylesheet\"\n"
     ]
    }
   ],
   "source": [
    "# printing the soup will print the full soup object [very long if completely printed][not pretty]\n",
    "print(str(soup)[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output looks pretty similar to what you see at the top of the inspect element console in figure 1.<br>\n",
    "Additionally, you may notice that there is no formatting involved. When the soup object is printed like a string, a newline will simply create a newline without indenting to highlight the nested structure of the HTML.\n",
    "<br>\n",
    "<br>\n",
    "Let's try and make this a little prettier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Quotes to Scrape\n",
      "  </title>\n",
      "  <link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
      "  <link href=\"/static/main.css\" \n"
     ]
    }
   ],
   "source": [
    "# second try [also long if completely printed][prettier]\n",
    "print(soup.prettify()[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `prettify()` function prints the soup object with it's nested hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>\n",
      " <a href=\"/login\">\n",
      "  Login\n",
      " </a>\n",
      "</p>\n",
      "\n",
      "-------\n",
      "<p class=\"text-muted\">\n",
      " Quotes by:\n",
      " <a href=\"https://www.goodreads.com/quotes\">\n",
      "  GoodReads.com\n",
      " </a>\n",
      "</p>\n",
      "\n",
      "-------\n",
      "<p class=\"copyright\">\n",
      " Made with\n",
      " <span class=\"sh-red\">\n",
      "  ❤\n",
      " </span>\n",
      " by\n",
      " <a href=\"https://scrapinghub.com\">\n",
      "  Scrapinghub\n",
      " </a>\n",
      "</p>\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "# soup object can be iterated; let's print the first 5 p tags\n",
    "for tag in soup.find_all('p'):\n",
    "    print(tag.prettify())\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_all` function will recursively traverse the all of the tags in the soup object. You can pass a string with the name of a tag to find all of that tag in the soup. I passed 'p' to find all 'p' tags in the soup.<br> \n",
    "\n",
    "I printed the line of hyphens to visualize where tags ended. <br>\n",
    "All three tags in the webpage were printed using the prettify function to highlight any child tags that belonged to the p tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>\n",
      "<a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
      "</h1>\n"
     ]
    }
   ],
   "source": [
    "# get a specific tag\n",
    "h1_tag = soup.find('h1')\n",
    "print(h1_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find()` method acts the same as `find_all()` but returns the first tag found.<br>\n",
    "This is the same as calling this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>\n",
       "<a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
       "</h1>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also call for a tag sort of like an attribute directly from the soup object\n",
    "<br><br>\n",
    "If the tag you're looking for isn't in the soup or you incorrectly name the attribute you will get a `NoneType` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "print(soup.h7) # h7 is a non-existant tag.\n",
    "print(type(soup.h7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a second to understand some BeautifulSoup objects. This will potentially help troubleshooting down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soup type: <class 'bs4.BeautifulSoup'> \n",
      "\n",
      "tag type: <class 'bs4.element.Tag'> \n",
      "\n",
      "tag attributes: {'href': '/', 'style': 'text-decoration: none'} \n",
      "\n",
      "tag text type <class 'bs4.element.NavigableString'>\n"
     ]
    }
   ],
   "source": [
    "# check out the object types\n",
    "a_tag = soup.a # first a tag\n",
    "\n",
    "print('soup type:',type(soup),'\\n')\n",
    "print('tag type:',type(a_tag),'\\n')\n",
    "print('tag attributes:',a_tag.attrs,'\\n')\n",
    "print('tag text type',type(a_tag.string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soup object and tag object are unsurprisingly called BeautifulSoup and Tag, respectively.<br>\n",
    "Attributes of tags are Python dictionaries, and the text of a tag is a NavigableString.<br>\n",
    "Documentation for the BeautifulSoup native objects can be found on their site linked at the top of this notebook.\n",
    "<br><br><br>\n",
    "### A new example\n",
    "Say one were to pull all div tags containing quotes.\n",
    "<br><br>\n",
    "After inspecting the source html, you can see that each of these tags have a class attribute equal to \"quote\". You can specify to `find_all()` to find a specific tag with a specific class.<br>\n",
    "Be careful, though. There may be more tags on the webpage with the same class value that you're searching for, which can return unwanted tags. I checked for this example though, and there aren't any more div tags with a class value of \"quote\" other than the ones we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      " <span class=\"text\" itemprop=\"text\">\n",
      "  “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      " </span>\n",
      " <span>\n",
      "  by\n",
      "  <small class=\"author\" itemprop=\"author\">\n",
      "   Albert Einstein\n",
      "  </small>\n",
      "  <a href=\"/author/Albert-Einstein\">\n",
      "   (about)\n",
      "  </a>\n",
      " </span>\n",
      " <div class=\"tags\">\n",
      "  Tags:\n",
      "  <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n",
      "  <a class=\"tag\" href=\"/tag/change/page/1/\">\n",
      "   change\n",
      "  </a>\n",
      "  <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">\n",
      "   deep-thoughts\n",
      "  </a>\n",
      "  <a class=\"tag\" href=\"/tag/thinking/page/1/\">\n",
      "   thinking\n",
      "  </a>\n",
      "  <a class=\"tag\" href=\"/tag/world/page/1/\">\n",
      "   world\n",
      "  </a>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pull all of the div tags containing quotes\n",
    "tag_list = []\n",
    "for tag in soup.find_all('div',{\"class\": \"quote\"}):\n",
    "    tag_list.append(tag)\n",
    " \n",
    "first_div = tag_list[0]\n",
    "print(first_div.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our expedition was successful (for the first tag, at least).\n",
    "<br>\n",
    "This div tag has all quote data that we care about in it.\n",
    "<br>\n",
    "<br>\n",
    "Now, let's see what happens when we call `get_text()` on an object with children tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "by Albert Einstein\n",
      "(about)\n",
      "\n",
      "\n",
      "            Tags:\n",
      "            \n",
      "change\n",
      "deep-thoughts\n",
      "thinking\n",
      "world\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(first_div.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all of the text for the tags within this div become concatenated when we call `get_text()`.\n",
    "<br>\n",
    "Let's isolate the quote followed by the author's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "---\n",
      "Albert Einstein\n"
     ]
    }
   ],
   "source": [
    "print(first_div.span.get_text())\n",
    "print('---')\n",
    "print(first_div.small.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice\n",
    "<br><br>\n",
    "### Moving down a quote\n",
    "Let's use some of BeautifulSoup's built-in versatile methods to navigate the tree.<br>\n",
    "By calling the `next_sibling` attribute of a tag, we can get the next tag in the tree.<br>\n",
    "Let's call that on our Albert Einstein quote to retrieve the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "<span class=\"text\" itemprop=\"text\">“It is our choices, Harry, that show what we truly are, far more than our abilities.”</span>\n",
      "<span>by <small class=\"author\" itemprop=\"author\">J.K. Rowling</small>\n",
      "<a href=\"/author/J-K-Rowling\">(about)</a>\n",
      "</span>\n",
      "<div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" content=\"abilities,choices\" itemprop=\"keywords\"/>\n",
      "<a class=\"tag\" href=\"/tag/abilities/page/1/\">abilities</a>\n",
      "<a class=\"tag\" href=\"/tag/choices/page/1/\">choices</a>\n",
      "</div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "next_div = first_div.next_sibling.next_sibling\n",
    "print(next_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure why, but for some reason `first_div.next_sibling` alone returned an empty NavigableString object, not the following tag that I was expecting.<br>\n",
    "I tacked on another `next_sibling` and I was able to get the tag I was expecting.\n",
    "<br><br>\n",
    "\n",
    "`previous_sibling` has the same function but it moves in the opposite direction\n",
    "<br><br>\n",
    "### Getting children and parents\n",
    "`parent` and `children` follow the same syntax as `next_sibling`. However, these two attributes act differently.<br>\n",
    "Let's take a look at the data types that they produce to get a better idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent data type:  <class 'bs4.element.Tag'> \n",
      "\n",
      "children data type:  <class 'list_iterator'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('parent data type: ',type(first_div.parent),'\\n')\n",
    "print('children data type: ',type(first_div.children),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`parent` returns the \"parent\" tag, while `children` returns an iterator to be able to iterate through children belonging to a tag.<br>\n",
    "Let's take a look at how to iterate through children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----\n",
      "<span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>\n",
      "----\n",
      "\n",
      "\n",
      "----\n",
      "<span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
      "<a href=\"/author/Albert-Einstein\">(about)</a>\n",
      "</span>\n",
      "----\n",
      "\n",
      "\n",
      "----\n",
      "<div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n",
      "<a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n",
      "<a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n",
      "<a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n",
      "<a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n",
      "</div>\n",
      "----\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for child in first_div.children:\n",
    "    print(child)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`children` returns tags that are direct children."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing parts of the soup\n",
    "Let's see how to get rid of Albert Einstein's quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully decomposed tag\n",
      "successfully decomposed tag\n",
      "successfully decomposed tag\n"
     ]
    }
   ],
   "source": [
    "for tag in soup.find_all('small'):\n",
    "    if tag.get_text() == 'Albert Einstein':\n",
    "        try:\n",
    "            tag.parent.parent.decompose()\n",
    "            print('successfully decomposed tag')\n",
    "        except Exception as e:\n",
    "            print(e,'could not decompose tag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decomposing parts of the soup is useful if you need to trim extraneous data before processing\n",
    "<br><br><br>\n",
    "Next, we'll see how to pull tags based on attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J.K. Rowling\n",
      "Jane Austen\n",
      "Marilyn Monroe\n",
      "André Gide\n",
      "Thomas A. Edison\n",
      "Eleanor Roosevelt\n",
      "Steve Martin\n"
     ]
    }
   ],
   "source": [
    "# pull tags based on attributes\n",
    "for tag in soup.find_all():\n",
    "    if 'class' in tag.attrs and 'author' in tag.attrs['class']:\n",
    "        print(tag.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is handy in situations where data may exist in the HTML, but you're not exactly sure where it is all of the time.\n",
    "<br>\n",
    "It's also critical to check to make sure the attribute you're searching for is actually in the dictionary, otherwise your program will crash.<br>\n",
    "Error checking with BeautifulSoup may make your code verbose, but much more resilient in the long run.\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "### Using selectors\n",
    "It is possible to search by selectors in BeautifulSoup.<br>\n",
    "This example selector is the top tag on the webpage. I pulled this selector directly from Google Chrome so it's a little verbose. A shorter selector may also work too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"tag\" href=\"/tag/love/\" style=\"font-size: 28px\">love</a>]\n"
     ]
    }
   ],
   "source": [
    "# pull the same tag every scrape by specifying a selector\n",
    "tag = soup.select('body > div > div:nth-child(2) > div.col-md-4.tags-box > span:nth-child(2) > a')\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note about error handling in Beautiful soup\n",
    "- Always ensure the site you're scraping isn't down\n",
    "- Make sure you're referencing \"View source\" rather than \"Inspect element\"\n",
    "- Double check the soup object by printing it out and inspecting it. Some sites may block scrapers entirely\n",
    "- Double check the data type of the object you're working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# how to print the http code\n",
    "print(str(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An important distinction\n",
    "\n",
    "`soup.find_all()` returns all tags<br>\n",
    "`soup.find()` returns one tag<br>\n",
    "`soup.select_one()` returns the first tag matching the selector<br>\n",
    "`soup.select()` returns all tags matching the selector<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
