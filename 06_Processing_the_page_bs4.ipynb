{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Webpages with BeautifulSoup\n",
    "\n",
    "Welcome! This module will be a walkthrough to processing web data with the popular Python package BeautifulSoup.\n",
    "\n",
    "BeautifulSoup has a terrific [webpage for documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) that has in-depth installation instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the hood of a webpage\n",
    "\n",
    "![](images/toscrape_screenshot.png)\n",
    "\n",
    "**Figure 1**: Every part of a webpage is generated from the underlying HTML. BeautifulSoup makes it easy to get this data and do cool things with it.\n",
    "\n",
    "#### Fortunately\n",
    "You don't need to know HTML to use BeautifulSoup, but it certainly helps.\n",
    "For example, if you know what you want from looking at the webpage, you may not understand how to HTML works underneath which will limit what your efficiency with BeautifulSoup. Otherwise, the more about HTML you know, the more effective a tool BeautifulSoup will be.\n",
    "<br><br><br>\n",
    "### Creating a soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the soup object \n",
    "url = 'http://quotes.toscrape.com'\n",
    "r  = requests.get(url)\n",
    "data = r.text\n",
    "soup = BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>Quotes to Scrape</title>\n",
      "<link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
      "<link href=\"/static/main.css\" rel=\"stylesheet\"\n"
     ]
    }
   ],
   "source": [
    "# printing the soup will print the full soup object [very long if completely printed][not pretty]\n",
    "print(str(soup)[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output looks pretty similar to what you see at the top of the inspect element console in figure 1.<br>\n",
    "Additionally, you may notice that there is no formatting involved. When the soup object is printed like a string, a newline will simply create a newline without indenting to highlight the nested structure of the HTML.\n",
    "<br>\n",
    "<br>\n",
    "Let's try and make this a little prettier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Quotes to Scrape\n",
      "  </title>\n",
      "  <link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
      "  <link href=\"/static/main.css\" \n"
     ]
    }
   ],
   "source": [
    "# second try [also long if completely printed][prettier]\n",
    "print(soup.prettify()[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `prettify()` function prints the soup object with it's nested hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>\n",
      " <a href=\"/login\">\n",
      "  Login\n",
      " </a>\n",
      "</p>\n",
      "\n",
      "-------\n",
      "<p class=\"text-muted\">\n",
      " Quotes by:\n",
      " <a href=\"https://www.goodreads.com/quotes\">\n",
      "  GoodReads.com\n",
      " </a>\n",
      "</p>\n",
      "\n",
      "-------\n",
      "<p class=\"copyright\">\n",
      " Made with\n",
      " <span class=\"sh-red\">\n",
      "  ❤\n",
      " </span>\n",
      " by\n",
      " <a href=\"https://scrapinghub.com\">\n",
      "  Scrapinghub\n",
      " </a>\n",
      "</p>\n",
      "\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "# soup object can be iterated; let's print the first 5 p tags\n",
    "for tag in soup.find_all('p'):\n",
    "    print(tag.prettify())\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_all` function will recursively traverse the all of the tags in the soup object. You can pass a string with the name of a tag to find all of that tag in the soup. I passed 'p' to find all 'p' tags in the soup.<br> \n",
    "\n",
    "I printed the line of hyphens to visualize where tags ended. <br>\n",
    "All three tags in the webpage were printed using the prettify function to highlight any child tags that belonged to the p tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>\n",
      "<a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
      "</h1>\n"
     ]
    }
   ],
   "source": [
    "# get a specific tag\n",
    "h1_tag = soup.find('h1')\n",
    "print(h1_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find()` method acts the same as `find_all()` but returns the first tag found.<br>\n",
    "This is the same as calling this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>\n",
       "<a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
       "</h1>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also call for a tag sort of like an attribute directly from the soup object\n",
    "<br><br>\n",
    "If the tag you're looking for isn't in the soup or you incorrectly name the attribute you will get a `NoneType` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "print(soup.h7) # h7 is a non-existant tag.\n",
    "print(type(soup.h7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a second to understand some BeautifulSoup objects. This will potentially help troubleshooting down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soup type: <class 'bs4.BeautifulSoup'> \n",
      "\n",
      "tag type: <class 'bs4.element.Tag'> \n",
      "\n",
      "tag attributes: {'href': '/', 'style': 'text-decoration: none'} \n",
      "\n",
      "tag text type <class 'bs4.element.NavigableString'>\n"
     ]
    }
   ],
   "source": [
    "# check out the object types\n",
    "a_tag = soup.a # first a tag\n",
    "\n",
    "print('soup type:',type(soup),'\\n')\n",
    "print('tag type:',type(a_tag),'\\n')\n",
    "print('tag attributes:',a_tag.attrs,'\\n')\n",
    "print('tag text type',type(a_tag.string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soup object and tag object are unsurprisingly called BeautifulSoup and Tag, respectively.<br>\n",
    "Attributes of tags are Python dictionaries, and the text of a tag is a NavigableString.<br>\n",
    "Documentation for the BeautifulSoup native objects can be found on their site linked at the top of this notebook.\n",
    "<br><br><br>\n",
    "### A new example\n",
    "Say one were to pull all div tags containing quotes.\n",
    "<br><br>\n",
    "After inspecting the source html, you can see that each of these tags have a class attribute equal to \"quote\". You can specify to `find_all()` to find a specific tag with a specific class.<br>\n",
    "Be careful, though. There may be more tags on the webpage with the same class value that you're searching for, which can return unwanted tags. I checked for this example though, and there aren't any more div tags with a class value of \"quote\" other than the ones we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      " <span class=\"text\" itemprop=\"text\">\n",
      "  “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      " </span>\n",
      " <span>\n",
      "  by\n",
      "  <small class=\"author\" itemprop=\"author\">\n",
      "   Albert Einstein\n",
      "  </small>\n",
      "  <a href=\"/author/Albert-Einstein\">\n",
      "   (about)\n",
      "  </a>\n",
      " </span>\n",
      " <div class=\"tags\">\n",
      "  Tags:\n",
      "  <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n",
      "  <a class=\"tag\" href=\"/tag/change/page/1/\">\n",
      "   change\n",
      "  </a>\n",
      "  <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">\n",
      "   deep-thoughts\n",
      "  </a>\n",
      "  <a class=\"tag\" href=\"/tag/thinking/page/1/\">\n",
      "   thinking\n",
      "  </a>\n",
      "  <a class=\"tag\" href=\"/tag/world/page/1/\">\n",
      "   world\n",
      "  </a>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pull all of the div tags containing quotes\n",
    "tag_list = []\n",
    "for tag in soup.find_all('div',{\"class\": \"quote\"}):\n",
    "    tag_list.append(tag)\n",
    " \n",
    "first_div = tag_list[0]\n",
    "print(first_div.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our expedition was successful (for the first tag, at least).\n",
    "<br>\n",
    "This div tag has all quote data that we care about in it.\n",
    "<br>\n",
    "<br>\n",
    "Now, let's see what happens when we call `get_text()` on an object with children tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "by Albert Einstein\n",
      "(about)\n",
      "\n",
      "\n",
      "            Tags:\n",
      "            \n",
      "change\n",
      "deep-thoughts\n",
      "thinking\n",
      "world\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(first_div.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all of the text for the tags within this div become concatenated when we call `get_text()`.\n",
    "<br>\n",
    "Let's isolate the quote followed by the author's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "---\n",
      "Albert Einstein\n"
     ]
    }
   ],
   "source": [
    "print(first_div.span.get_text())\n",
    "print('---')\n",
    "print(first_div.small.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice\n",
    "<br><br>\n",
    "### Moving down a quote\n",
    "Let's use some of BeautifulSoup's built-in versatile methods to navigate the tree.<br>\n",
    "By calling the `next_sibling` attribute of a tag, we can get the next tag in the tree.<br>\n",
    "Let's call that on our Albert Einstein quote to retrieve the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "<span class=\"text\" itemprop=\"text\">“It is our choices, Harry, that show what we truly are, far more than our abilities.”</span>\n",
      "<span>by <small class=\"author\" itemprop=\"author\">J.K. Rowling</small>\n",
      "<a href=\"/author/J-K-Rowling\">(about)</a>\n",
      "</span>\n",
      "<div class=\"tags\">\n",
      "            Tags:\n",
      "            <meta class=\"keywords\" content=\"abilities,choices\" itemprop=\"keywords\"/>\n",
      "<a class=\"tag\" href=\"/tag/abilities/page/1/\">abilities</a>\n",
      "<a class=\"tag\" href=\"/tag/choices/page/1/\">choices</a>\n",
      "</div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "next_div = first_div.next_sibling.next_sibling\n",
    "print(next_div)\n",
    "#print(next_div.span.get_text())\n",
    "#print('---')\n",
    "#print(next_div.small.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move sideways\n",
    "example_tag.next_sibling\n",
    "example_tag.previous_sibling\n",
    "\n",
    "# move up\n",
    "print(type(example_tag.parent))\n",
    "print(type(example_tag.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of jk rowling quotes\n",
    "url = 'http://quotes.toscrape.com/'\n",
    "r  = requests.get(url)\n",
    "data = r.text\n",
    "soup = BeautifulSoup(data)\n",
    "\n",
    "for tag in soup.find_all('small'):\n",
    "    if tag.get_text() == 'J.K. Rowling':\n",
    "        try:\n",
    "            tag.parent.parent.decompose()\n",
    "            print('successfully decomposed tag')\n",
    "        except Exception as e:\n",
    "            print(e,'could not decompose tag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull tags based on attributes\n",
    "for tag in soup.find_all():\n",
    "    if 'class' in tag.attrs and 'author' in tag.attrs['class']:\n",
    "        print(tag.get_text())\n",
    "        \n",
    "    # don't do this because the attribute value may be a list\n",
    "    #if 'class' in tag.attrs and tag.attrs['class'] == 'author':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the same tag every scrape by specifying a selector\n",
    "tag = soup.select('body > div > div:nth-child(2) > div.col-md-4.tags-box > span:nth-child(2) > a')\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error handling\n",
    "\n",
    "# check to ensure the site isnt down\n",
    "print(str(r))\n",
    "\n",
    "# when in doubt, check the data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/http_responses.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An important distinction\n",
    "\n",
    "`soup.find_all()` returns all tags<br>\n",
    "`soup.find()` returns one tag<br>\n",
    "`soup.select_one()` returns the first tag matching the selector<br>\n",
    "`soup.select()` returns all tags matching the selector<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
